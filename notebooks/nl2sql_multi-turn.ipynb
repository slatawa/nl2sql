{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn SQL Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/conda/lib/python310.zip', '/home/jupyter/git_repo/nl2sql-generic/nl2sql_src', '../', '/opt/conda/lib/python3.10', '/opt/conda/lib/python3.10/lib-dynload', '', '/opt/conda/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys  \n",
    "sys.path.insert(1, '../')\n",
    "sys.path.insert(1, '/home/jupyter/git_repo/nl2sql-generic/nl2sql_src')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "from vertexai.preview.generative_models import GenerativeModel, GenerationResponse, Tool\n",
    "from nl2sql_generic import Nl2sqlBq\n",
    "\n",
    "from proto.marshal.collections import repeated\n",
    "from proto.marshal.collections import maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'sl-test-project-353312'\n",
    "DATASET_ID = 'zoominfo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing when metadata cache is already created\n",
    "metadata_cache_file = \"../nl2sql_src/cache_metadata/metadata_cache.json\"\n",
    "nl2sqlbq_client = Nl2sqlBq(project_id=PROJECT_ID, dataset_id=DATASET_ID, metadata_json_path = metadata_cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Initiated\n"
     ]
    }
   ],
   "source": [
    "PGPROJ = \"sl-test-project-353312\"\n",
    "PGLOCATION = 'us-central1'\n",
    "PGINSTANCE = \"test-nl2sql\"\n",
    "PGDB = \"test-db\"\n",
    "PGUSER = \"postgres\"\n",
    "PGPWD = \"test-nl2sql\"\n",
    "nl2sqlbq_client.init_pgdb(PGPROJ, PGLOCATION, PGINSTANCE, PGDB, PGUSER, PGPWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(resp: GenerationResponse):\n",
    "    part = resp.candidates[0].content.parts[0]\n",
    "    try:\n",
    "        text = part.text\n",
    "    except:\n",
    "        text = None\n",
    "    return text\n",
    "\n",
    "def prior_sql_result(question)->str:\n",
    "    # Execute the SQL and return the result\n",
    "    return \"Test output for question : \" + question\n",
    "\n",
    "\n",
    "def call_api(name: str, args: str) -> str:\n",
    "    if name == \"prior_sql_tool\":\n",
    "        return prior_sql_result(args)\n",
    "\n",
    "\n",
    "def recurse_proto_repeated_composite(repeated_object):\n",
    "    repeated_list = []\n",
    "    for item in repeated_object:\n",
    "        if isinstance(item, repeated.RepeatedComposite):\n",
    "            item = recurse_proto_repeated_composite(item)\n",
    "            repeated_list.append(item)\n",
    "        elif isinstance(item, maps.MapComposite):\n",
    "            item = recurse_proto_marshal_to_dict(item)\n",
    "            repeated_list.append(item)\n",
    "        else:\n",
    "            repeated_list.append(item)\n",
    "\n",
    "    return repeated_list\n",
    "\n",
    "def recurse_proto_marshal_to_dict(marshal_object):\n",
    "    new_dict = {}\n",
    "    for k, v in marshal_object.items():\n",
    "      if not v:\n",
    "        continue\n",
    "      elif isinstance(v, maps.MapComposite):\n",
    "          v = recurse_proto_marshal_to_dict(v)\n",
    "      elif isinstance(v, repeated.RepeatedComposite):\n",
    "          v = recurse_proto_repeated_composite(v)\n",
    "      new_dict[k] = v\n",
    "\n",
    "    return new_dict\n",
    "\n",
    "previous_sql_spec = {\n",
    "    \"name\": \"prior_sql_tool\",\n",
    "    \"description\": \"Provides the SQL query that is generated for the previous question\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The natural language question for which the SQL query was generated\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"question\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_function_name(response: GenerationResponse):\n",
    "  return response.candidates[0].content.parts[0].function_call.name\n",
    "\n",
    "def get_function_args(response: GenerationResponse) -> dict:\n",
    "  return recurse_proto_marshal_to_dict(response.candidates[0].content.parts[0].function_call.args)\n",
    "\n",
    "\n",
    "sql_tools = Tool.from_dict(\n",
    "    {\n",
    "        \"function_declarations\":[previous_sql_spec]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vertexai.preview.generative_models import GenerativeModel\n",
    "model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "\n",
    "table_chat = model.start_chat()\n",
    "sql_chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_response(chat_model, prompt) -> str:\n",
    "    responses = chat_model.send_message(prompt, stream=True)\n",
    "    output = []\n",
    "    for response in responses:\n",
    "        output.append(response.candidates[0].content.parts[0].text)\n",
    "    return \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"How many people are enrolled in CalFresh?\",\n",
    "             \"How many of them live in Los Angeles County?\"\n",
    "            ]\n",
    "\n",
    "# questions = [\"How many Black individuals are served across CalHHS programs?\",\n",
    "#              \"What is the breakdown by program?\",\n",
    "#              \"Has this changed over time?\",\n",
    "#              \"Change over time by program?\"\n",
    "#             ]\n",
    "\n",
    "question = questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"wic-redemptions-by-vendor-county-with-family-counts-2021-2022-part-c\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.2916865348815918\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.16344544291496277\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.2040245532989502\n",
       "    severity: HARM_SEVERITY_LOW\n",
       "    severity_score: 0.21157968044281006\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.2639787197113037\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.1445106565952301\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.1489114761352539\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.054701510816812515\n",
       "  }\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 2856\n",
       "  candidates_token_count: 31\n",
       "  total_token_count: 2887\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_prompt = nl2sqlbq_client.table_filter_promptonly(\"Table identification initiation\")\n",
    "# print(table_prompt)\n",
    "table_chat.send_message(table_prompt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table identified for queestion :' How many people are enrolled in CalFresh? ' is:  medi-cal-and-calfresh-enrollment\n",
      "Table identified for queestion :' How many of them live in Los Angeles County? ' is:  medi-cal-and-calfresh-enrollment\n"
     ]
    }
   ],
   "source": [
    "q_prompt_template = \"\"\"Using the context in the chat history, identify the table name that is most probable to contain the data requested for the question given below.\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "for question in questions:\n",
    "    q_prompt = q_prompt_template.format(question=question)\n",
    "    table_identified = get_chat_response(table_chat, q_prompt)\n",
    "    print(\"Table identified for queestion :'\", question, \"' is: \", table_identified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table identified for queestion :' How many people are enrolled in CalFresh? ' is:  medi-cal-and-calfresh-enrollment\n",
      "Trying to read the index file ../../nl2sql-generic/nl2sql_src/cache_metadata/saved_index_pgdata\n",
      "Generated SQL for question :  How many people are enrolled in CalFresh?  is \n",
      "  ```sql\n",
      "SELECT \n",
      "  COALESCE(SUM(SAFE_CAST(Number_of_Beneficiaries AS INT64)), 0) AS total_enrolled_in_calfresh\n",
      "FROM \n",
      "  `bigquery-public-data.dhcs_medi_cal.medi_cal_and_calfresh_enrollment`\n",
      "WHERE \n",
      "  Program = 'CalFresh Only' OR Program = 'CalFresh and Medi-Cal';\n",
      "```\n",
      "Table identified for queestion :' How many of them live in Los Angeles County? ' is:  medi-cal-and-calfresh-enrollment\n",
      "Trying to read the index file ../../nl2sql-generic/nl2sql_src/cache_metadata/saved_index_pgdata\n",
      "Generated SQL for question :  How many of them live in Los Angeles County?  is \n",
      "  ```sql\n",
      "SELECT \n",
      "  COALESCE(SUM(SAFE_CAST(Number_of_Beneficiaries AS INT64)), 0) AS total_enrolled_in_calfresh\n",
      "FROM \n",
      "  `bigquery-public-data.dhcs_medi_cal.medi_cal_and_calfresh_enrollment`\n",
      "WHERE \n",
      "  (\n",
      "    Program = 'CalFresh Only' \n",
      "    OR \n",
      "    Program = 'CalFresh and Medi-Cal'\n",
      "  )\n",
      "  AND\n",
      "  County = 'Los Angeles'\n",
      ";\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    q_prompt = q_prompt_template.format(question=question)\n",
    "    table_identified = get_chat_response(table_chat, q_prompt)\n",
    "    print(\"Table identified for queestion :'\", question, \"' is: \", table_identified)\n",
    "\n",
    "    try:\n",
    "        previous_question_sql = sql_chat.history[-1]\n",
    "    except:\n",
    "        previous_question_sql = \"\"\n",
    "\n",
    "    sql_prompt = nl2sqlbq_client.generate_sql_few_shot_promptonly(question, table_name=table_identified, prev_sql=previous_question_sql)\n",
    "    # print(sql_prompt)\n",
    "    sql_gen = get_chat_response(sql_chat, sql_prompt)\n",
    "    print(\"Generated SQL for question : \", question, \" is \\n \", sql_gen)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to read the index file ../../nl2sql-generic/nl2sql_src/cache_metadata/saved_index_pgdata\n",
      "Function to call prior_sql_tool\n",
      "function call arguments = {'question': 'How has participation in CalFresh changed since 2015?'}\n",
      "Test output for question : How has participation in CalFresh changed since 2015?\n"
     ]
    }
   ],
   "source": [
    "question = \"How has participation in CalFresh changed since 2015?\"\n",
    "table_identified = get_chat_response(table_chat, q_prompt)\n",
    "previous_question_sql=\"\"\n",
    "sql_prompt = nl2sqlbq_client.generate_sql_few_shot_promptonly(question, table_name=table_identified, prev_sql=previous_question_sql)\n",
    "\n",
    "sql_chat = model.start_chat()\n",
    "\n",
    "sql_resp = sql_chat.send_message(sql_prompt, tools=[sql_tools])\n",
    "txt = get_text(sql_resp)\n",
    "if txt:\n",
    "    print(\"Response from chat\", txt)\n",
    "else:\n",
    "    fname = get_function_name(sql_resp)\n",
    "    # fname = sql_resp.candidates[0].content.parts[0].function_call.name\n",
    "    print(\"Function to call\", fname)\n",
    "    func_args = get_function_args(sql_resp)\n",
    "    # fargs = sql_resp.candidates[0].content.parts[0].function_call.args\n",
    "    print(\"function call arguments =\", func_args)\n",
    "    print(call_api(fname, func_args['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[role: \"user\"\n",
       " parts {\n",
       "   text: \"\\nOnly use the following tables meta-data:\\n\\n```\\nTable Name : medi-cal-and-calfresh-enrollment\\n\\nDescription: This table provides information about the enrollment of individuals in Medi-Cal and CalFresh programs in different counties. This information in this table can be used to calculate the ratio of beneficiaries and service providers for a particular program\\n\\nThis table has the following columns : \\nEligiblity_Date                     (STRING) : . \\nCounty                     (STRING) : . \\nProgram                     (STRING) : . It contains values : \\\"CalFresh Only\\\", \\\"CalFresh only\\\", \\\"CalFresh and Medi-Cal\\\".\\nNumber_of_Beneficiaries                     (INTEGER) : . \\nANNOTATION_CODE                     (INTEGER) : . \\nCOUNT_ANNOTATION_DESC                     (STRING) : . It contains values : \\\"Cell Suppressed For Small Numbers\\\".\\n\\n\\n\\n```\\n\\nYou are an SQL expert at generating SQL queries from a natural language question. Given the input question, create a syntactically correct Biguery query to run.\\n\\nOnly use the few relevant columns given in the question.\\nPay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table. Do not use more than 10 columns in the query. Focus on the keywords indicating calculation. \\nPlease think step by step and always validate the reponse.\\nrecitify each column names by referencing them from the meta-data.\\nUse the following examples as guidelines to generate the new BigQuery SQL accordingly\\n\\nQuestion: How many Hispanic individuals are served across CalHHS programs?\\nSQL : SELECT  COALESCE(SUM(SAFE_CAST( Hispanic   AS INT64)), 0) AS total_hispanics FROM `cdii-poc.HHS_Program_Counts.calhhs-dashboard-2015-2020-annual-data-file` ; \\n\\nQuestion: How has participation in CalWorks changed since 2015?\\nSQL : select  year, sum(total_beneficiaries) as total_beneficiaries, round(ifnull(100 * (sum(total_beneficiaries)/lag(sum(total_beneficiaries)) over(order by year asc) - 1), 0), 2)  AS percentage_change from \\n(SELECT fileyear AS year,  SUM(SAFE_CAST( Person   AS INT64)) total_beneficiaries, FROM `cdii-poc.HHS_Program_Counts.calhhs-dashboard-2015-2020-annual-data-file`  AS annual_file WHERE (Program = \\'CalWorks\\') group by year ORDER BY year)\\n group by year order by year; \\n\\nQuestion:  How do CalWorks program participation trends differ by race and ethnicity?\\nSQL : SELECT COALESCE(SUM(SAFE_CAST( White   AS INT64)), 0) AS calhhs_dashboard_2015_2020_annual_data_file_total_whites_1, COALESCE(SUM(SAFE_CAST( Black   AS INT64)), 0) AS calhhs_dashboard_2015_2020_annual_data_file_total_blacks_1, COALESCE(SUM(SAFE_CAST( Hispanic   AS INT64)), 0) AS calhhs_dashboard_2015_2020_annual_data_file_total_hispanics_1, COALESCE(SUM(SAFE_CAST( Asian_PI   AS INT64)), 0) AS calhhs_dashboard_2015_2020_annual_data_file_total_asian_1, COALESCE(SUM(SAFE_CAST( Native_American   AS INT64)), 0) AS calhhs_dashboard_2015_2020_annual_data_file_total_native_american_1 FROM `cdii-poc.HHS_Program_Counts.calhhs-dashboard-2015-2020-annual-data-file`  WHERE (Program ) = \\'CalWorks\\'; \\n\\n\\n\\n\\n\\nFor this question what would be the most accurate SQL query?\\nQuestion: How has participation in CalFresh changed since 2015?\\n\"\n",
       " },\n",
       " role: \"model\"\n",
       " parts {\n",
       "   function_call {\n",
       "     name: \"prior_sql_tool\"\n",
       "     args {\n",
       "       fields {\n",
       "         key: \"question\"\n",
       "         value {\n",
       "           string_value: \"How has participation in CalFresh changed since 2015?\"\n",
       "         }\n",
       "       }\n",
       "     }\n",
       "   }\n",
       " }]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_chat.history"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu113.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu113:m118"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
