{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn SQL Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys  \n",
    "sys.path.insert(1, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "from vertexai.preview.generative_models import GenerativeModel, GenerationResponse, Tool\n",
    "from nl2sql_generic import Nl2sqlBq\n",
    "\n",
    "from proto.marshal.collections import repeated\n",
    "from proto.marshal.collections import maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing when metadata cache is already created\n",
    "metadata_cache_file = \"../nl2sql_src/cache_metadata/metadata_cache.json\"\n",
    "nl2sqlbq_client = Nl2sqlBq(project_id=\"sl-test-project-353312\", dataset_id=\"EY\", metadata_json_path = metadata_cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Initiated\n"
     ]
    }
   ],
   "source": [
    "PGPROJ = \"sl-test-project-353312\"\n",
    "PGLOCATION = 'us-central1'\n",
    "PGINSTANCE = \"test-nl2sql\"\n",
    "PGDB = \"test-db\"\n",
    "PGUSER = \"postgres\"\n",
    "PGPWD = \"test-nl2sql\"\n",
    "nl2sqlbq_client.init_pgdb(PGPROJ, PGLOCATION, PGINSTANCE, PGDB, PGUSER, PGPWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(resp: GenerationResponse):\n",
    "    part = resp.candidates[0].content.parts[0]\n",
    "    try:\n",
    "        text = part.text\n",
    "    except:\n",
    "        text = None\n",
    "    return text\n",
    "\n",
    "def prior_sql_result(question)->str:\n",
    "    # Execute the SQL and return the result\n",
    "    return \"Test output for question : \" + question\n",
    "\n",
    "\n",
    "def call_api(name: str, args: str) -> str:\n",
    "    if name == \"prior_sql_tool\":\n",
    "        return prior_sql_result(args)\n",
    "\n",
    "\n",
    "def recurse_proto_repeated_composite(repeated_object):\n",
    "    repeated_list = []\n",
    "    for item in repeated_object:\n",
    "        if isinstance(item, repeated.RepeatedComposite):\n",
    "            item = recurse_proto_repeated_composite(item)\n",
    "            repeated_list.append(item)\n",
    "        elif isinstance(item, maps.MapComposite):\n",
    "            item = recurse_proto_marshal_to_dict(item)\n",
    "            repeated_list.append(item)\n",
    "        else:\n",
    "            repeated_list.append(item)\n",
    "\n",
    "    return repeated_list\n",
    "\n",
    "def recurse_proto_marshal_to_dict(marshal_object):\n",
    "    new_dict = {}\n",
    "    for k, v in marshal_object.items():\n",
    "      if not v:\n",
    "        continue\n",
    "      elif isinstance(v, maps.MapComposite):\n",
    "          v = recurse_proto_marshal_to_dict(v)\n",
    "      elif isinstance(v, repeated.RepeatedComposite):\n",
    "          v = recurse_proto_repeated_composite(v)\n",
    "      new_dict[k] = v\n",
    "\n",
    "    return new_dict\n",
    "\n",
    "previous_sql_spec = {\n",
    "    \"name\": \"prior_sql_tool\",\n",
    "    \"description\": \"Provides the SQL query that is generated for the previous question\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The natural language question for which the SQL query was generated\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"question\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_function_name(response: GenerationResponse):\n",
    "  return response.candidates[0].content.parts[0].function_call.name\n",
    "\n",
    "def get_function_args(response: GenerationResponse) -> dict:\n",
    "  return recurse_proto_marshal_to_dict(response.candidates[0].content.parts[0].function_call.args)\n",
    "\n",
    "\n",
    "sql_tools = Tool.from_dict(\n",
    "    {\n",
    "        \"function_declarations\":[previous_sql_spec]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vertexai.preview.generative_models import GenerativeModel\n",
    "model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "\n",
    "table_chat = model.start_chat()\n",
    "sql_chat = model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_response(chat_model, prompt) -> str:\n",
    "    responses = chat_model.send_message(prompt, stream=True)\n",
    "    output = []\n",
    "    for response in responses:\n",
    "        output.append(response.candidates[0].content.parts[0].text)\n",
    "    return \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"How many people are enrolled in CalFresh?\",\n",
    "             \"How many of them live in Los Angeles County?\"\n",
    "            ]\n",
    "\n",
    "# questions = [\"How many Black individuals are served across CalHHS programs?\",\n",
    "#              \"What is the breakdown by program?\",\n",
    "#              \"Has this changed over time?\",\n",
    "#              \"Change over time by program?\"\n",
    "#             ]\n",
    "\n",
    "question = questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"preterm-and-very-preterm-births-by-raceethnicity-2010-2018\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.364325106\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.162512898\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.212395355\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.19072403\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.244002536\n",
       "    severity: HARM_SEVERITY_LOW\n",
       "    severity_score: 0.220510259\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.15571934\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.0992954\n",
       "  }\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 2875\n",
       "  candidates_token_count: 27\n",
       "  total_token_count: 2902\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_prompt = nl2sqlbq_client.table_filter_promptonly(\"Table identification initiation\")\n",
    "# print(table_prompt)\n",
    "table_chat.send_message(table_prompt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table identified for queestion :' How many people are enrolled in CalFresh? ' is:  medi-cal-and-calfresh-enrollment\n",
      "Table identified for queestion :' How many of them live in Los Angeles County? ' is:  medi-cal-and-calfresh-enrollment\n"
     ]
    }
   ],
   "source": [
    "q_prompt_template = \"\"\"Using the context in the chat history, identify the table name that is most probable to contain the data requested for the question given below.\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "for question in questions:\n",
    "    q_prompt = q_prompt_template.format(question=question)\n",
    "    table_identified = get_chat_response(table_chat, q_prompt)\n",
    "    print(\"Table identified for queestion :'\", question, \"' is: \", table_identified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table identified for queestion :' How many people are enrolled in CalFresh? ' is:  medi-cal-and-calfresh-enrollment\n",
      "Trying to read the index file ../../nl2sql-generic/nl2sql_src/cache_metadata/saved_index_pgdata\n",
      "Generated SQL for question :  How many people are enrolled in CalFresh?  is \n",
      "  ```\n",
      "SELECT  COALESCE(SUM(Number_of_Beneficiaries), 0) AS total_beneficiaries\n",
      "FROM `cdii-poc.Medi-Cal_and_Calfresh_Enrollment.medi-cal-and-calfresh-enrollment` \n",
      "WHERE Program = 'CalFresh only'\n",
      "```\n",
      "Table identified for queestion :' How many of them live in Los Angeles County? ' is:  medi-cal-and-calfresh-enrollment\n",
      "Trying to read the index file ../../nl2sql-generic/nl2sql_src/cache_metadata/saved_index_pgdata\n",
      "Generated SQL for question :  How many of them live in Los Angeles County?  is \n",
      "  ```sql\n",
      "SELECT  COALESCE(SUM(Number_of_Beneficiaries), 0) AS total_beneficiaries\n",
      "FROM `cdii-poc.Medi-Cal_and_Calfresh_Enrollment.medi-cal-and-calfresh-enrollment` \n",
      "WHERE Program = 'CalFresh only' AND County = 'Los Angeles'\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    q_prompt = q_prompt_template.format(question=question)\n",
    "    table_identified = get_chat_response(table_chat, q_prompt)\n",
    "    print(\"Table identified for queestion :'\", question, \"' is: \", table_identified)\n",
    "\n",
    "    try:\n",
    "        previous_question_sql = sql_chat.history[-1]\n",
    "    except:\n",
    "        previous_question_sql = \"\"\n",
    "\n",
    "    sql_prompt = nl2sqlbq_client.generate_sql_few_shot_promptonly(question, table_name=table_identified, prev_sql=previous_question_sql)\n",
    "    # print(sql_prompt)\n",
    "    sql_gen = get_chat_response(sql_chat, sql_prompt)\n",
    "    print(\"Generated SQL for question : \", question, \" is \\n \", sql_gen)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to read the index file ../../nl2sql-generic/nl2sql_src/cache_metadata/saved_index_pgdata\n",
      "Function to call prior_sql_tool\n",
      "function call arguments = {'question': 'How has participation in CalFresh changed since 2015?'}\n",
      "Test output for question : How has participation in CalFresh changed since 2015?\n"
     ]
    }
   ],
   "source": [
    "question = \"How has participation in CalFresh changed since 2015?\"\n",
    "table_identified = get_chat_response(table_chat, q_prompt)\n",
    "previous_question_sql=\"\"\n",
    "sql_prompt = nl2sqlbq_client.generate_sql_few_shot_promptonly(question, table_name=table_identified, prev_sql=previous_question_sql)\n",
    "\n",
    "sql_chat = model.start_chat()\n",
    "\n",
    "sql_resp = sql_chat.send_message(sql_prompt, tools=[sql_tools])\n",
    "txt = get_text(sql_resp)\n",
    "if txt:\n",
    "    print(\"Response from chat\", txt)\n",
    "else:\n",
    "    fname = get_function_name(sql_resp)\n",
    "    # fname = sql_resp.candidates[0].content.parts[0].function_call.name\n",
    "    print(\"Function to call\", fname)\n",
    "    func_args = get_function_args(sql_resp)\n",
    "    # fargs = sql_resp.candidates[0].content.parts[0].function_call.args\n",
    "    print(\"function call arguments =\", func_args)\n",
    "    print(call_api(fname, func_args['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_chat.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from prompts import * \n",
    "metadata_json_path = \"../nl2sql_src/cache_metadata/metadata_cache.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_table_details(table_name):\n",
    "    f = open(metadata_json_path, encoding=\"utf-8\")\n",
    "    metadata_json = json.loads(f.read())\n",
    "        \n",
    "    table_json = metadata_json[table_name]\n",
    "    columns_json = table_json[\"Columns\"]\n",
    "    columns_info = \"\"\n",
    "    for column_name in columns_json:\n",
    "        column = columns_json[column_name]            \n",
    "        column_info = f\"\"\"{column[\"Name\"]} \\\n",
    "                    ({column[\"Type\"]}) : {column[\"Description\"]}. {column[\"Examples\"]}\\n\"\"\"\n",
    "        columns_info = columns_info + column_info\n",
    "        \n",
    "    prompt = Table_info_template.format(table_name = table_name,\n",
    "                                        table_description = metadata_json[table_name]['Description'],\n",
    "                                        columns_info = columns_info)\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name_1 = \"calhhs-dashboard-2015-2020-annual-data-file\"\n",
    "table_name_2 = \"medi-cal-and-calfresh-enrollment\"\n",
    "table_1 = return_table_details(table_name_1)\n",
    "table_2 = return_table_details(table_name_2)\n",
    "sample_question = \"Which five counties have the lowest number of CalFresh authorized vendors compared to CalFresh participants?\"\n",
    "sample_sql = \"\"\"SELECT Vendor_Location,(vendor_cnt/total_participants)*100 as vendor_participants_ratio FROM\n",
    "((SELECT TRIM(Vendor_Location) AS Vendor_Location,COALESCE(SUM(SAFE_CAST(_Number_of_Participants_Redeemed_ AS INT64))) as total_participants FROM `cdii-poc.HHS_Program_Counts.calfresh-redemption-by-county-by-participant-category-data-2010-2018`  group by Vendor_Location) as participants\n",
    "JOIN\n",
    "(SELECT TRIM(COUNTY) AS COUNTY,count(VENDOR) as vendor_cnt FROM `cdii-poc.HHS_Program_Counts.women-infants-and-children-wic-authorized-vendors` \n",
    "group by COUNTY having COUNTY is not null) as vendors\n",
    "ON UPPER(participants.Vendor_Location)=UPPER(vendors.COUNTY))\n",
    "WHERE (vendor_cnt/total_participants)*100 is not null\n",
    "order by vendor_participants_ratio asc limit 5;\"\"\"\n",
    "\n",
    "question = \"Which counties have the highest and lowest ratios of providers to enrolled participants in Medi-cal?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_prompt = join_prompt_template.format(table_1 = table_1,\n",
    "                                          table_2 = table_2,\n",
    "                                          question = question)\n",
    "join_prompt_one_shot = join_prompt_template_one_shot.format(table_1 = table_1,\n",
    "                                          table_2 = table_2,\n",
    "                                          sample_question = sample_question,\n",
    "                                          sample_sql = sample_sql,\n",
    "                                          question = question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero shot prompting :\n",
      " ```sql\n",
      "SELECT\n",
      "  County,\n",
      "  ROUND((\n",
      "      Number_of_Beneficiaries /\n",
      "      COUNT(DISTINCT Number)\n",
      "    ), 2) AS Provider_to_Beneficiary_Ratio\n",
      "FROM medi_cal_and_calfresh_enrollment AS mce\n",
      "JOIN calhhs_dashboard_2015_2020_annual_data_file AS cdf\n",
      "  ON mce.County = cdf.Number\n",
      "WHERE\n",
      "  cdf.Program = 'MediCal'\n",
      "GROUP BY\n",
      "  County\n",
      "ORDER BY\n",
      "  Provider_to_Beneficiary_Ratio DESC,\n",
      "  Provider_to_Beneficiary_Ratio ASC\n",
      "LIMIT 10;\n",
      "```\n",
      "One-shot prompt: \n",
      " ```sql\n",
      "SELECT \n",
      "  t1.County,\n",
      "  SUM(t2.`Number_of_Beneficiaries`) / COUNT(DISTINCT t1.`Number`) AS beneficiaries_per_provider\n",
      "FROM \n",
      "  `calhhs-dashboard-2015-2020-annual-data-file` AS t1\n",
      "JOIN \n",
      "  `medi-cal-and-calfresh-enrollment` AS t2\n",
      "ON \n",
      "  t1.`Number` = t2.`County`\n",
      "WHERE \n",
      "  t2.`Program` = 'Medi-Cal and CalFresh'\n",
      "GROUP BY \n",
      "  t1.`County`\n",
      "ORDER BY \n",
      "  beneficiaries_per_provider DESC\n",
      "LIMIT \n",
      "  1;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "resp = model.generate_content(join_prompt)\n",
    "print(\"Zero shot prompting :\\n\", resp.text)\n",
    "\n",
    "resp = model.generate_content(join_prompt_one_shot)\n",
    "print(\"One-shot prompt: \\n\", resp.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fserv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
